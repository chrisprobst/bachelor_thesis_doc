%!TEX root = bachelor.tex

\chapter{Conclusion}
\label{conclusion}

As shown in Chapter \ref{evaluation}, the implementation of the Chunked-Swarm model using the super seeder extension, see \ref{theory:model:chunkedswarm}, is able to distribute data sets among a variable number of peers within $2\:*\:T_0$ seconds, where $T_0$ is the time for transferring a data set from one peer to another, as long as there are not too many peers overwhelming the system. Also, an overwhelmed system can get out of step, which can lead to unfair chunk distribution, where one peer distributes more chunks as it should, while an other peer distribute nothing at all. Thus, the solution works in general, but might drop performance under high pressure.

The main reason for this effect is the pull based approach. Every peer explicitely request chunks from other peers. At first, only the super seeder can offer chunks. The peers receive announcements and start downloading chunks from the super seeder. These chunks are distinct from each other, because the super seeder rejects download requests of chunks, which have already been uploaded to other peers. Then, every peer announces and uploads its own chunk to the other peers. If a peer A completes its chunk download from the super seeder too early, it might happen, that another peer B requests this chunk from peer A, which will be transferred really fast, since there is no other peer requesting this chunk yet. Then, the other peers try to download the chunk and notice, that there are two peers offering this chunk. If peer A just finished another chunk, the remaining peers would request the chunk from peer B, because a chunk is always requested from the peer, which offers least. But peer B have also its own distinct chunk from the super seeder. This chunk must be distributed by peer B, because no one else has this chunk. This means, peer B is now responsible for two chunks, while peer A is waiting for requests. A large number of peers or a high chunk count factor can increase the possibility for this situation.

Unfortunately, this is a fundamental problem of the pull based approach, because the peers do not know which chunks other peers request. While this approach is good to prevent chunk duplication, see \ref{module:algorithm:chunkedswarm}, it ignores some information the system already knows. If a peer A successfully downloads a chunk from the super seeder, this chunk is not present in the Peer-to-Peer network yet. So this chunk must be distributed through peer A. Also, peer A basically knows, that all other peers want this chunk as well, so waiting for explicit requests seems counterintuitive. A push based approach would solve these issues. A peer pushes chunks from the super seeder to every other peer in the network. So a peer is not allowed to push a chunk, that was not received from the super seeder earlier. This way, the load is distributed evenly across all peers. Also, there is no need for chunk announcements anymore, see \ref{module:core:net:annoucements}. Therefore, the system scales better in the large, while latency is reduced significantly.

Another problem is the Java programming language. As explained in Section \ref{evaluation:456}, Java does not support stack allocation of class instances. Since the pull based approach creates a lot of small data structures, the heap memory of the application grows rapidly and thus causes garbage collection to run more often. The impact has been observed using the \emph{jvisualvm} tool provided by \emph{Oracle}. A future implementation is strongly encouraged to implement some sort of manual object pooling or to use a runtime, which supports stack allocations in the first place.