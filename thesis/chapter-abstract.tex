%!TEX root = bachelor.tex

\pdfbookmark[0]{Abstract}{abstract}
\begin{center} 
\huge Abstract
\end{center}


This thesis concentrates on implementing and evaluating different distribution algorithms for generic data transfers in large-scale \emph{Peer-to-Peer} networks, especially for incremental transfers, which yields the possibillity for video streaming. The main focus is on $1:n$ scenarios, where only one peer has a complete data set and $n$ peers try to distribute this data set among themselves as fast as possible.

The main problem is the choice of the best distribution algorithm, which should be able to use most of the available network bandwidth of all participating peers. In a traditional client\,/\,server system, the server uploads the data set to all clients sequentially, which means that only the server upload bandwidth is used but none of the client upload bandwidths.

Peer-to-Peer networks in combination with efficient distribution algorithms can help to solve this particular problem. These algorithms are always based on the same technique, where all participating peers download specific chunks from the peer, which has the complete data set and upload these chunks to other peers as well. This way, the peers help to distribute the data set using their own upload bandwidth. The difficulty is the choice of the specific chunks the peers download and the tuning of parameters like chunk count and chunk size.

In the course of this thesis, three distribution models are developed and evaluated. The main goal is to find a distribution model, that can distribute a data set evenly among all peers within $2\:*\:T_0$ seconds, where $T_0$ is the time to transfer the data set from one peer to another. Only the \emph{Chunked-Swarm} model was able to keep this limit. Therefore, the majority of the evaluation is dedicated to this model.

The evaluation of the Chunked-Swarm model shows, that this model works fine in general, but has some performance issues under high pressure. These issues are mostly based on the choice of the programming language, which is Java, and the pull based approach, which causes an exponentially growing amount of overhead. 